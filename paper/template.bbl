\begin{thebibliography}{10}

\bibitem{nips11}
Yasin Abbasi-Yadkori, D{\'a}vid P{\'a}l, and Csaba Szepesv{\'a}ri.
\newblock Improved algorithms for linear stochastic bandits.
\newblock {\em Advances in neural information processing systems}, 24, 2011.

\bibitem{MABappsurvey}
Djallel Bouneffouf, Irina Rish, and Charu Aggarwal.
\newblock Survey on applications of multi-armed and contextual bandits.
\newblock In {\em 2020 IEEE Congress on Evolutionary Computation (CEC)}, pages
  1--8. IEEE, 2020.

\bibitem{experiment_design}
Giuseppe Burtini, Jason Loeppky, and Ramon Lawrence.
\newblock A survey of online experiment design with the stochastic multi-armed
  bandit.
\newblock {\em arXiv preprint arXiv:1510.00757}, 2015.

\bibitem{Freedman+}
Xiequan Fan.
\newblock Freedmanâ€™s inequality with non-bounded martingale differences.
\newblock {\em arXiv preprint arXiv:1404.4776}, 2014.

\bibitem{GLMpaper}
Sarah Filippi, Olivier Cappe, Aur{\'e}lien Garivier, and Csaba Szepesv{\'a}ri.
\newblock Parametric bandits: The generalized linear case.
\newblock {\em Advances in Neural Information Processing Systems}, 23, 2010.

\bibitem{Freedman1975}
David~A Freedman.
\newblock On tail probabilities for martingales.
\newblock {\em the Annals of Probability}, pages 100--118, 1975.

\bibitem{First_Heteroscedastic}
Johannes Kirschner and Andreas Krause.
\newblock Information directed sampling and bandits with heteroscedastic noise.
\newblock In {\em Conference On Learning Theory}, pages 358--384. PMLR, 2018.

\bibitem{UCBpaper}
Tze~Leung Lai, Herbert Robbins, et~al.
\newblock Asymptotically efficient adaptive allocation rules.
\newblock {\em Advances in applied mathematics}, 6(1):4--22, 1985.

\bibitem{banditbook}
Tor Lattimore and Csaba Szepesv{\'a}ri.
\newblock {\em Bandit algorithms}.
\newblock Cambridge University Press, 2020.

\bibitem{VFreedman}
Gen Li, Changxiao Cai, Yuxin Chen, Yuantao Gu, Yuting Wei, and Yuejie Chi.
\newblock Is q-learning minimax optimal? a tight sample complexity analysis.
\newblock {\em arXiv preprint arXiv:2102.06548}, 2021.

\bibitem{news_recommendation}
Lihong Li, Wei Chu, John Langford, and Robert~E Schapire.
\newblock A contextual-bandit approach to personalized news article
  recommendation.
\newblock In {\em Proceedings of the 19th international conference on World
  wide web}, pages 661--670, 2010.

\bibitem{Xiang23}
Xiang Li and Qiang Sun.
\newblock Variance-aware robust reinforcement learning with linear function
  approximation with heavy-tailed rewards.
\newblock {\em arXiv preprint arXiv:2303.05606}, 2023.

\bibitem{Medina16}
Andres~Munoz Medina and Scott Yang.
\newblock No-regret algorithms for heavy-tailed linear bandits.
\newblock In {\em International Conference on Machine Learning}, pages
  1642--1650. PMLR, 2016.

\bibitem{GFApaper}
Daniel Russo and Benjamin Van~Roy.
\newblock Eluder dimension and the sample complexity of optimistic exploration.
\newblock {\em Advances in Neural Information Processing Systems}, 26, 2013.

\bibitem{Shao18}
Han Shao, Xiaotian Yu, Irwin King, and Michael~R Lyu.
\newblock Almost optimal algorithms for linear stochastic bandits with
  heavy-tailed payoffs.
\newblock {\em Advances in Neural Information Processing Systems}, 31, 2018.

\bibitem{Thompson33}
William~R Thompson.
\newblock On the likelihood that one unknown probability exceeds another in
  view of the evidence of two samples.
\newblock {\em Biometrika}, 25(3-4):285--294, 1933.

\bibitem{Xue20}
Bo~Xue, Guanghui Wang, Yimu Wang, and Lijun Zhang.
\newblock Nearly optimal regret for stochastic linear bandits with heavy-tailed
  payoffs.
\newblock {\em arXiv preprint arXiv:2004.13465}, 2020.

\bibitem{Zhou21}
Dongruo Zhou, Quanquan Gu, and Csaba Szepesvari.
\newblock Nearly minimax optimal reinforcement learning for linear mixture
  markov decision processes.
\newblock In {\em Conference on Learning Theory}, pages 4532--4576. PMLR, 2021.

\end{thebibliography}
